---
layout: post
title:  "LeNet 대충 정리하기"
categories: DeepLearning
author: bactoria
---

* content
{:toc}

1년 전, 캐글스터디를 하면서 발표했던 적이 있다. CNN 에 대해서 발표했었다. 

우연히 대전에 있었던 [1st 함께하는 딥러닝 컨퍼런스](https://tykimos.github.io/2018/06/28/ISS_1st_Deep_Learning_Conference_All_Together/)에서 서포터즈로 활동하면서 딥러닝 고수님들의 강연을 듣고, 저녁에는 식사까지 함께 하는 기회가 있어서 좋았다. 곧바로 부산에서 캐글스터디를 진행하면서 작년 여름방학에는 CNN쪽을 계속 공부했던 것 같다.

당시 학습했던 것들은 다음과 같다.

- 밑바닥부터 시작하는 딥러닝 (책)
- 스탠포드 CS231n 강의
- mnist (kaggle)
- TGS Salt Competition (kaggle)
- Deep Photo Style Transfer (논문)
- 테리의 딥러닝 토크 (동아대 강연)

작년에 캐글스터디에서 내가 발표했던 PPT를 최근 우연히 보게 되었는데, 거의 다 까먹은 것 같다.

그 때 글을 남겼으면 참 좋았을 텐데... 더 까먹기 전에 글로 대충이라도 남기려고 한다.

## 딥러닝이 무엇이냐?

머신러닝으로 어떻게하면 강아지와 베이글을 잘 분류할 수 있을까?

강아지와 베이글의 차이를 가지는 하나하나 Feature를 뽑아줘야 하는데, 머신러닝으로는 쉽지가 않다.

피쳐를 뽑는 것 자체가 피쳐로 뽑지 않았던 것을 하나 하나 다 날려버리는 행위다.

딥러닝에서는 피쳐를 뽑지 않는다. 이미지를 넣고 아웃풋이 나오는 end-to-end 방식이다. 사람이 피쳐를 뽑지 않는다.

## CNN

> Convolutional Neural Network (합성곱 신경망)

CNN은 필터를 학습하는 것임.

![image](https://user-images.githubusercontent.com/25674959/60757274-6e94a880-a043-11e9-8aa5-481f5123031a.png)

1 0 1  
0 1 0  
1 0 1  

노란 정사각형이 중요한 것임. 한 에폭마다 이것을 계속 픽스해나가는 것이고, 학습의 최종 산출물은 결국 필터들이다.

&nbsp;

## LeNet

![image](https://user-images.githubusercontent.com/25674959/60757336-2d50c880-a044-11e9-9cef-0cf111c47910.png)

&nbsp;

### Convolutions

![image](https://user-images.githubusercontent.com/25674959/60758251-2a5bd500-a050-11e9-8cc5-686eda743980.png)

- Input
  - 3
- Filter
  - 5x5 필터 6개
- Output
  - 필터를 거친 28x28 이미지 6개
- 총 파라미터 개수
  - ( 5*5 필터 + bias ) * 6
  - (25 + 1) * 6 = 156

&nbsp;

### Subsampling

![image](https://user-images.githubusercontent.com/25674959/60757957-347bd480-a04c-11e9-880f-08a800a44fdc.png)

- 오버피팅 방지
- depth 변화가 없다.
- FC레이어에 파라미터를 감소시킨다.
 
![image](https://user-images.githubusercontent.com/25674959/60758074-c46e4e00-a04d-11e9-965f-14dc0b880d40.png)

&nbsp;

### Convolutions

![image](https://user-images.githubusercontent.com/25674959/60758087-f2ec2900-a04d-11e9-9fe0-0a7642720298.png)

&nbsp;

### Subsampling

![image](https://user-images.githubusercontent.com/25674959/60758289-a524f000-a050-11e9-8be9-2492eb80a2a2.png)

&nbsp;

### Full Connection

![image](https://user-images.githubusercontent.com/25674959/60758297-c1c12800-a050-11e9-947d-2994df1feb1b.png)

&nbsp;

### 결과

![image](https://user-images.githubusercontent.com/25674959/60758311-e9b08b80-a050-11e9-8398-a8925efeb449.png)

우리의 모델에 3을 넣으면 0~9까지의 output이 나온다.

[3]이 가장 높으므로 3이라고 인식한다.

이 값들은 우리는 수만~수백만 데이터를 가지고 지도학습한 결과이며,

데이터를 학습시킬 때 마다 조금씩 조금씩 필터를 픽스하며 로스를 줄여나간다.


폰트도 원래 배민 한나체였는데 포맷하면서 폰트다깨짐ㅋㅋ

발표할 때 로스펑션이랑 그라디언트에 대해서 언급했는지는 잘 모르겠지만, 지금 명확하게 어떤게 있고 그런지는 기억이 가물가물하네.

캐글 3회차 경품이 구글디벨로퍼 우산이던데 열심히해서 받아야쥐
